{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# !pip install efficient_apriori\n",
    "# !pip install fptools\n",
    "# !import fptools as fp\n",
    "# !pip install mlxtend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7501, 20)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./Market_Basket_Optimisation.csv',header=None)\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions=[]\n",
    "for i in range(0,dataset.shape[0]):\n",
    "    temp=[]\n",
    "    for j in range(0,dataset.shape[1]):\n",
    "        if str(dataset.values[i,j])!='nan':\n",
    "            temp.append(str(dataset.values[i,j]))\n",
    "    transactions.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用  apriori 方案求解  \n",
    "def rules1():\n",
    "    print(\"方案一：\")\n",
    "    from efficient_apriori import apriori\n",
    "    start=time.time()\n",
    "    items,rules=apriori(transactions,min_support=0.04,min_confidence=0.2)\n",
    "    print('频繁项集：',items)\n",
    "    print('关联规则：',rules)\n",
    "\n",
    "    end=time.time()\n",
    "    print('efficient_apriori 用时：',end-start)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 采用  fptools的FP-growth方案求解 \n",
    "# fis = [iset for iset in fp.frequent_itemsets(transactions, 3)]\n",
    "# mfis = [iset for iset in fp.maximal_frequent_itemsets(transactions, 3)]\n",
    "\n",
    "# print(fis)\n",
    "# print(mfis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "def encode_units1(x):\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules2():\n",
    "    print(\"方案二：\")\n",
    "    # 采用mlxtend.frequent_patterns \n",
    "    # dataset=dataset.set_index('Transaction')['Item']\n",
    "    # dataset['Item']=dataset['Item'].str.lower()\n",
    "    # dataset=dataset.dropdata[data.Item =='none'].index\n",
    "    # dataset.set_index('')\n",
    "    from  mlxtend.frequent_patterns  import apriori\n",
    "    from  mlxtend.frequent_patterns  import association_rules\n",
    "    # pd.options.display.max_columns=100\n",
    "    start=time.time()\n",
    "\n",
    "#     transactions.rename(columns={'Transaction': 'Item'}) \n",
    "    df=pd.DataFrame(transactions).stack().reset_index() #\n",
    "    df=df.rename({'level_0': 'LA', 0: 'LC'},axis='columns')# ,inplace=True)\n",
    "    df=df.groupby(['LA','LC'])['LA'].count().unstack().reset_index().fillna(0).set_index('LA')\n",
    "    transaction=df.applymap(encode_units)\n",
    "#     transactiontemp=[]\n",
    "#     for index, row in transaction.iterrows():\n",
    "#         temp=[]\n",
    "#         for j in row :\n",
    "#             if j!='nan'\n",
    "#                 temp.append(j)\n",
    "#         transactiontemp.append(temp)\n",
    "        \n",
    "#     print(index)\n",
    "    print(transaction.shape)\n",
    "#     print(transaction)\n",
    "#     transaction = pd.DataFrame(transactiion.stack().groupby(level=0).apply(list).tolist(),columns=list(['Transaction','Item']))\t# 方法一\n",
    "# #     def deal(data):\n",
    "# #         return data.dropna().tolist()\n",
    "# #     transaction = transactions.apply(deal,axis=1).tolist()\n",
    "\n",
    "# #     print(transactiona)\n",
    "    \n",
    "#     # 采用one-hot 编码格式\n",
    "#     hot_encoded_df=data.groupby(['Transaction','Item'])['Item'].count().unstack().reset_index().fillna(0).set_index('Transaction')\n",
    "#     hot_encoded_df = hot_encoded_df.applymap(encode_units)\n",
    "    frequent_itemsets = apriori(transaction, min_support=0.1, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.3)\n",
    "    print('频繁项集：',frequent_itemsets)\n",
    "    print('关联规则：',rules)#[(rules['lift']>=1 ) &(rules['confidence'] >= 0.2) ])# 过滤\n",
    "\n",
    "    end=time.time()\n",
    "    print('mlxtend.frequent_patterns  用时：',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "方案一：\n",
      "频繁项集： {1: {('honey',): 356, ('mineral water',): 1788, ('green tea',): 991, ('shrimp',): 536, ('frozen smoothie',): 475, ('olive oil',): 494, ('salmon',): 319, ('low fat yogurt',): 574, ('eggs',): 1348, ('burgers',): 654, ('turkey',): 469, ('milk',): 972, ('whole wheat rice',): 439, ('french fries',): 1282, ('soup',): 379, ('frozen vegetables',): 715, ('spaghetti',): 1306, ('cookies',): 603, ('cooking oil',): 383, ('champagne',): 351, ('chicken',): 450, ('chocolate',): 1229, ('tomatoes',): 513, ('pancakes',): 713, ('grated cheese',): 393, ('fresh bread',): 323, ('ground beef',): 737, ('escalope',): 595, ('herb & pepper',): 371, ('cake',): 608}, 2: {('milk', 'mineral water'): 360, ('eggs', 'mineral water'): 382, ('mineral water', 'spaghetti'): 448, ('ground beef', 'mineral water'): 307, ('chocolate', 'mineral water'): 395}}\n",
      "关联规则： [{mineral water} -> {milk}, {milk} -> {mineral water}, {mineral water} -> {eggs}, {eggs} -> {mineral water}, {spaghetti} -> {mineral water}, {mineral water} -> {spaghetti}, {ground beef} -> {mineral water}, {mineral water} -> {chocolate}, {chocolate} -> {mineral water}]\n",
      "efficient_apriori 用时： 0.5100293159484863\n",
      "----------------------------------------------------------------------------------------------------\n",
      "方案二：\n",
      "(7501, 120)\n",
      "频繁项集：     support         itemsets\n",
      "0  0.163845      (chocolate)\n",
      "1  0.179709           (eggs)\n",
      "2  0.170911   (french fries)\n",
      "3  0.132116      (green tea)\n",
      "4  0.129583           (milk)\n",
      "5  0.238368  (mineral water)\n",
      "6  0.174110      (spaghetti)\n",
      "关联规则： Empty DataFrame\n",
      "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction]\n",
      "Index: []\n",
      "mlxtend.frequent_patterns  用时： 0.7300419807434082\n"
     ]
    }
   ],
   "source": [
    "rules1() \n",
    "print('-'*100) \n",
    "rules2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
